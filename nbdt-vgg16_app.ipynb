{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2941e8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vichshir/miniconda3/envs/nn/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "stty: 'standard input': Inappropriate ioctl for device\n",
      "/home/vichshir/miniconda3/envs/nn/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough values to unpack (expected 2, got 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/vichshir/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/vichshir/miniconda3/envs/nn/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/vichshir/miniconda3/envs/nn/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SoftNBDT(\n",
       "  (rules): SoftEmbeddedDecisionRules()\n",
       "  (model): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from nbdt.model import SoftNBDT\n",
    "from utils import load_vgg16, plot_decision_tree\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "classes = (\n",
    "    'airplane', 'car', 'bird', 'cat', 'deer', \n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    ")\n",
    "\n",
    "# load checkpoint\n",
    "state_dict = torch.load('./SoftNBDT_model.pt', map_location=torch.device('cpu'))\n",
    "model_weights = state_dict['state_dict']\n",
    "\n",
    "model = load_vgg16(num_classes=10).to(device)\n",
    "model_nbdt = SoftNBDT(model=model, dataset='CIFAR10', hierarchy='induced-vgg16')\n",
    "model_nbdt.load_state_dict(model_weights)\n",
    "model_nbdt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bacbbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_decision_tree(decisions, nbdt):\n",
    "    graph = nbdt.rules.tree.G\n",
    "    \n",
    "    labeldict = {}\n",
    "    for wnid, node in nbdt.rules.tree.wnid_to_node.items():\n",
    "        labeldict[wnid] = node.name\n",
    "\n",
    "    color_map = []\n",
    "    for node_name in list(labeldict.values()):\n",
    "        if node_name in list(map(lambda x: x['name'], decisions)):\n",
    "            color_map.append('royalblue')\n",
    "        else:\n",
    "            color_map.append('whitesmoke')\n",
    "\n",
    "    pos = nx.nx_agraph.graphviz_layout(graph, prog=\"dot\")\n",
    "    nx.draw(graph, pos, \n",
    "            labels=labeldict, \n",
    "            with_labels=True, \n",
    "            node_color=color_map, \n",
    "            node_size=1400, \n",
    "            font_color='black',\n",
    "            font_weight='bold',\n",
    "            font_family='sans-serif',\n",
    "            font_size=8,\n",
    "            edge_color='lightgray')\n",
    "    \n",
    "    path_pos = [pos[n['node'].wnid] for n in decisions[:-1]]\n",
    "    for idx, d in enumerate(decisions[1:]):\n",
    "        x, y = path_pos[idx]\n",
    "        prob = d['prob']\n",
    "        plt.text(x+5, y-30, s=f'Prob. {prob:.0%}', \n",
    "                 horizontalalignment='center', \n",
    "                 fontsize='x-small', \n",
    "                 color='darkcyan', \n",
    "                 fontweight='bold')\n",
    "    \n",
    "    plt.savefig('./temp_img.png')\n",
    "\n",
    "\n",
    "def show_image(img):\n",
    "    # preprocessing\n",
    "    img = cv2.resize(img, dsize=(32, 32), interpolation=cv2.INTER_LINEAR)\n",
    "    img_torch = (torch.tensor(img).movedim(-1, 0) / 255).unsqueeze(0).to(device)\n",
    "    \n",
    "    # get predicted label\n",
    "    pred_label = classes[torch.argmax(model_nbdt(img_torch), dim=1)]\n",
    "    \n",
    "    # generate decision plot\n",
    "    plot_decision_tree(model_nbdt.forward_with_decisions(img_torch)[1][0], model_nbdt)\n",
    "    fig = Image.open('./temp_img.png')\n",
    "    fig = np.asarray(fig)\n",
    "    os.remove('./temp_img.png')\n",
    "    \n",
    "    return pred_label, fig\n",
    "\n",
    "\n",
    "app = gr.Interface(\n",
    "    fn=show_image,\n",
    "    inputs=gr.Image(show_label=False),\n",
    "    outputs=[\n",
    "        gr.Label(label='Predicted Class'),\n",
    "        gr.Image(label='Why?')\n",
    "    ],\n",
    ")\n",
    "\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
